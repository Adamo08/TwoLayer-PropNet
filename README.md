# Neural Network Classifier (N2N) ğŸ¾âœ¨

This project implements a **two-layer artificial neural network (ANN)** for binary classification using NumPy, with dazzling training visualizations powered by Matplotlib and Seaborn. Whether you prefer static ğŸ“Š or live ğŸ¥ updates, this code tracks loss, accuracy, and even throws in a confusion matrix to show off its skills. The datasetâ€”featuring adorable cats ğŸ± and dogs ğŸ¶â€”is loaded from HDF5 files via a handy function in `utilities.py`.

The neural network rocks:
- An **Input Layer** (sized by the dataset features)
- A **Hidden Layer** (you pick the neuron count! ğŸ§ )
- An **Output Layer** (cat or dog? Binary magic! ğŸ¯)

## Features ğŸŒŸ
- Forward & backward propagation for training ğŸš€
- Log-loss cost function ğŸ“‰
- Gradient descent optimization âš™ï¸
- Accuracy tracking + confusion matrix fun ğŸ¨
- Loss & accuracy visuals over epochs (static or live!) ğŸŒˆ
- Dataset preprocessing (reshaping & normalizing) ğŸ”§

## Prerequisites âœ…
Youâ€™ll need Python 3.6+ installed ğŸ. Check `requirements.txt` for the full list of goodies.

### Installation ğŸ› ï¸
1. Clone or grab this repo:
   ```bash
   git clone https://github.com/Adamo08/TwoLayer-PropNet.git
   cd TwoLayer-PropNet
   ```
2. Install the dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Make sure `datasets/` has `trainset.hdf5` and `testset.hdf5` ready to roll! ğŸ¾

### Requirements ğŸ“¦
Hereâ€™s whatâ€™s in `requirements.txt`:
```
numpy
matplotlib
seaborn
scikit-learn
tqdm
h5py
```

Get them with:
```bash
pip install matplotlib seaborn scikit-learn tqdm numpy h5py
```

## File Structure ğŸ“‚
```
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ trainset.hdf5    # Training dataset (cat & dog pix! ğŸ±ğŸ¶)
â”‚   â””â”€â”€ testset.hdf5     # Test dataset (more furry friends!)
â”œâ”€â”€ utilities.py         # Helper functions (e.g., load_data) ğŸ› ï¸
â”œâ”€â”€ app.py               # Main script with ANN awesomeness ğŸŒŸ
â”œâ”€â”€ requirements.txt     # Required Python modules ğŸ“‹
â””â”€â”€ README.md            # Youâ€™re here! ğŸ‘‹
```

### Dataset ğŸ±ğŸ¶
The dataset is stored in HDF5 format and packed with images of **cats** and **dogs** for binary classification (cat = 0, dog = 1, or vice versaâ€”your call!). It includes:
- **Training Set**: `X_train` (images) & `y_train` (labels)
- **Test Set**: `X_test` (images) & `y_test` (labels)

Loaded via `load_data()` in `utilities.py`. ğŸ˜»

## Usage ğŸš€
1. Check that all files are in place.
2. Tweak hyperparameters in `app.py` if youâ€™re feeling fancy:
   - `n1`: Hidden layer neurons (default: 3) ğŸ§ 
   - `alpha`: Learning rate (default: 0.01) âš¡
   - `epochs`: Training rounds (default: 100) â³
3. Fire it up:
   ```bash
   python app.py
   ```

### Training Options ğŸ›ï¸
- **`N2N_NORMAL`**: Trains and shows static plotsâ€”loss, accuracy, and a confusion matrixâ€”when done. ğŸ“ˆ
- **`N2N_LIVE`**: Trains with live-updating loss & accuracy plots, plus a confusion matrix at the end. ğŸ¬

Switch it up in `app.py`:
```python
# Static vibes
params = N2N_NORMAL(X_train_reshape, y_train, 3, 0.01, 100)

# Live action
params = N2N_LIVE(X_train_reshape, y_train, 3, 0.01, 100)
```

### Outputs ğŸ‰
- **Console**: Final model accuracy ğŸ†
- **Plots**:
  - Loss & accuracy curves (saved during training) ğŸ“‰ğŸ“ˆ
  - Confusion matrix (saved as `confusion_matrix.png`) ğŸ¨
- **Sample Images**: A cute grid of cat & dog pics with labels before training starts! ğŸ–¼ï¸

## Code Overview ğŸ”
### Key Functions
- `initialize`: Sets up weights & biases âš–ï¸
- `Forward_Propagation`: Runs data through the network â¡ï¸
- `log_loss`: Measures the cost ğŸ“Š
- `Back_Propagation`: Calculates gradients â¬…ï¸
- `update`: Tweaks params with gradient descent ğŸ”§
- `predict`: Makes cat-or-dog calls ğŸ¾
- `Confusion_Matrix`: Plots the results ğŸ¯
- `N2N_NORMAL` / `N2N_LIVE`: Trains with style! ğŸŒŸ

### Preprocessing ğŸ› ï¸
- **Reshaping**: Flattens images (e.g., `(samples, height, width)` â†’ `(samples, features)`) ğŸ“
- **Normalization**: Scales pixels from `[0, 255]` to `[0, 1]` ğŸŒˆ

## Example ğŸŒŸ
Say your dataset has 1000 cat & dog pics (64x64 grayscale):
1. `X_train` shape: `(1000, 64, 64)`
2. After reshaping: `(1000, 4096)`
3. After transposition: `(4096, 1000)`
4. `y_train` shape: `(1, 1000)`

Run:
```bash
python app.py
```
Trains with 3 hidden neurons, a 0.01 learning rate, and 100 epochs. ğŸ±ğŸ¶

## Notes ğŸ“
- Built for binary classification (cat vs. dog, `n2 = 1`) ğŸ¾
- For bigger datasets, bump up `n1`, `alpha`, or `epochs` ğŸ”§
- Live plotting (`N2N_LIVE`) might lag a bit due to real-time updates â±ï¸

## License ğŸ“œ
Unlicensedâ€”free to use or tweak for fun & learning! ğŸ“

## Acknowledgments ğŸ™Œ
Inspired by classic neural network ideas and powered by Pythonâ€™s awesome data science tools. ğŸ˜
